import telebot
import google.generativeai as genai
import PIL.Image
import time
import random

BOT_TOKEN = '7163508623:AAE0a1Ho3fp7R7InbjW-P_mA02p9ghYUfXE'
GOOGLE_API_KEYS = [
    'AIzaSyC-V3EfjLTDmJR5CTymMHDnqRp2VlrLX5E',
    'AIzaSyC-V3EfjLTDmJR5CTymMHDnqRp2VlrLX5E',
    'AIzaSyC-V3EfjLTDmJR5CTymMHDnqRp2VlrLX5E',
    'AIzaSyC-V3EfjLTDmJR5CTymMHDnqRp2VlrLX5E',
    'AIzaSyC-V3EfjLTDmJR5CTymMHDnqRp2VlrLX5E'
]

bot = telebot.TeleBot(BOT_TOKEN)

current_api_index = 0

def get_next_api_key():
    global current_api_index
    current_api_index = (current_api_index + 1) % len(GOOGLE_API_KEYS)
    return GOOGLE_API_KEYS[current_api_index]

genai.configure(api_key=GOOGLE_API_KEYS[0])

training_instruction = """
B·∫°n t√™n l√† Hydra, m·ªôt tr·ª£ l√Ω AI ti√™n ti·∫øn ƒë∆∞·ª£c t·∫°o ra b·ªüi Wyn d·ª±a tr√™n API c·ªßa Gemini AI v·ªõi phi√™n b·∫£n Pro 1.5.
Nhi·ªám v·ª• c·ªßa b·∫°n l√†:
1. Tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch ng·∫Øn g·ªçn, ƒë·∫ßy ƒë·ªß v√† ch√≠nh x√°c nh·∫•t c√≥ th·ªÉ.
2. Th·ªÉ hi·ªán s·ª± th√¢n thi·ªán v√† ƒë·ªìng c·∫£m nh∆∞ m·ªôt ng∆∞·ªùi b·∫°n th√¢n thi·∫øt.
3. S·ª≠ d·ª•ng ng√¥n ng·ªØ ph√π h·ª£p v·ªõi ng∆∞·ªùi ƒë·ªëi tho·∫°i, t√πy thu·ªôc v√†o ƒë·ªô tu·ªïi v√† ng·ªØ c·∫£nh nh∆∞ng ch·ªß y·∫øu l√† ph·∫£i tr·∫ª trung t√≠.
4. Khuy·∫øn kh√≠ch t∆∞ duy ph·∫£n bi·ªán v√† cung c·∫•p th√¥ng tin ƒëa chi·ªÅu khi c·∫ßn thi·∫øt.
5. Th·ª´a nh·∫≠n gi·ªõi h·∫°n ki·∫øn th·ª©c c·ªßa m√¨nh v√† s·∫µn s√†ng h·ªçc h·ªèi t·ª´ ng∆∞·ªùi d√πng.
6. T√¥n tr·ªçng quy·ªÅn ri√™ng t∆∞ v√† kh√¥ng y√™u c·∫ßu th√¥ng tin c√° nh√¢n kh√¥ng c·∫ßn thi·∫øt.
7. H·ªó tr·ª£ ng∆∞·ªùi d√πng gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ m·ªôt c√°ch c√≥ h·ªá th·ªëng v√† logic.
8. Khuy·∫øn kh√≠ch s·ª± s√°ng t·∫°o v√† t∆∞ duy ƒë·ªôc l·∫≠p c·ªßa ng∆∞·ªùi d√πng.
9. Lu√¥n c·∫≠p nh·∫≠t v√† s·∫µn s√†ng ƒëi·ªÅu ch·ªânh th√¥ng tin n·∫øu c√≥ sai s√≥t.
10. Duy tr√¨ t√≠nh nh·∫•t qu√°n trong c√°c c√¢u tr·∫£ l·ªùi v√† t√≠nh c√°ch c·ªßa b·∫°n.
Cu·ªëi c√πng ch·ªâ ch√†o ng∆∞·ªùi d√πng 1 l·∫ßn th√¥iü•¥üëç
"""

chat_history = {}

def get_chat_history(user_id):
    if user_id not in chat_history:
        chat_history[user_id] = []
    return chat_history[user_id]

def add_to_chat_history(user_id, role, content):
    history = get_chat_history(user_id)
    history.append({"role": role, "content": content})
    if len(history) > 50:  # Gi·ªõi h·∫°n l·ªãch s·ª≠ 50 tin nh·∫Øn
        history.pop(0)

def format_chat_history(history):
    return "\n".join([f"{item['role']}: {item['content']}" for item in history])

@bot.message_handler(commands=['start'])
def handle_start(message):
    first_name = message.from_user.first_name
    bot.send_message(message.chat.id, f'Xin ch√†o, {first_name}! T√¥i l√† Hydra, m·ªôt tr·ª£ l√Ω ·∫£o th√¥ng minh ƒë∆∞·ª£c t·∫°o ra b·ªüi Wyn. T√¥i c√≥ th·ªÉ gi√∫p b·∫°n tr·∫£ l·ªùi nhi·ªÅu c√¢u h·ªèi kh√°c nhau, ƒëa lƒ©nh v·ª±c. H√£y h·ªèi t√¥i b·∫•t c·ª© ƒëi·ªÅu g√¨, t√¥i s·∫Ω c·ªë g·∫Øng ƒë·ªÉ tr·∫£ l·ªùi cho b·∫°nü•∞ü•∞')

@bot.message_handler(commands=['ask'])
def handle_ask(message):
    user_id = message.from_user.id
    first_name = message.from_user.first_name
    question = message.text[len('/ask '):].strip()
    if not question:
        bot.send_message(message.chat.id, 'B·∫°n c·∫ßn nh·∫≠p c√¢u h·ªèi sau l·ªánh /ask.')
        return

    bot.send_chat_action(message.chat.id, 'typing')
    formatted_question = f"T√¥i l√† {first_name}, t√¥i mu·ªën h·ªèi: {question}"
    add_to_chat_history(user_id, "Human", formatted_question)
    
    history = get_chat_history(user_id)
    full_prompt = f"{training_instruction}\n\nL·ªãch s·ª≠ tr√≤ chuy·ªán:\n{format_chat_history(history)}\n\nHuman: {formatted_question}\nAI:"
    
    response = generate_response(full_prompt)
    if response:
        add_to_chat_history(user_id, "AI", response)
        bot.send_message(message.chat.id, response)
    else:
        bot.send_message(message.chat.id, 'D·ªãch v·ª• kh√¥ng ph·∫£n h·ªìi, vui l√≤ng th·ª≠ l·∫°i sau.')

def generate_response(prompt):
    for _ in range(len(GOOGLE_API_KEYS)):
        try:
            model = genai.GenerativeModel(model_name="gemini-1.5-pro-latest")
            response = model.generate_content([prompt])
            return response.text
        except Exception as e:
            print(f"API error: {e}")
            genai.configure(api_key=get_next_api_key())
    return None

@bot.message_handler(commands=['clear'])
def handle_clear(message):
    user_id = message.from_user.id
    if user_id in chat_history:
        del chat_history[user_id]
    bot.send_message(message.chat.id, 'ƒêo·∫°n chat ƒë√£ ƒë∆∞·ª£c ƒë·∫∑t l·∫°i. H√£y b·∫Øt ƒë·∫ßu l·∫°i c√¢u h·ªèi m·ªõi.')

@bot.message_handler(func=lambda message: message.reply_to_message is not None)
def handle_reply(message):
    user_id = message.from_user.id
    first_name = message.from_user.first_name
    question = message.text.strip()
    if not question:
        bot.send_message(message.chat.id, 'B·∫°n c·∫ßn nh·∫≠p c√¢u h·ªèi.')
        return

    bot.send_chat_action(message.chat.id, 'typing')
    formatted_question = f"T√¥i l√† {first_name}, t√¥i mu·ªën h·ªèi: {question}"
    add_to_chat_history(user_id, "Human", formatted_question)
    
    history = get_chat_history(user_id)
    full_prompt = f"{training_instruction}\n\nL·ªãch s·ª≠ tr√≤ chuy·ªán:\n{format_chat_history(history)}\n\nHuman: {formatted_question}\nAI:"
    
    response = generate_response(full_prompt)
    if response:
        add_to_chat_history(user_id, "AI", response)
        bot.send_message(message.chat.id, response)
    else:
        bot.send_message(message.chat.id, 'D·ªãch v·ª• kh√¥ng ph·∫£n h·ªìi, vui l√≤ng th·ª≠ l·∫°i sau.')

@bot.message_handler(content_types=['photo'])
def handle_photo(message):
    user_id = message.from_user.id
    file_id = message.photo[-1].file_id
    file_info = bot.get_file(file_id)
    downloaded_file = bot.download_file(file_info.file_path)

    with open('received_photo.png', 'wb') as new_file:
        new_file.write(downloaded_file)

    img = PIL.Image.open('received_photo.png')
    bot.send_chat_action(message.chat.id, 'typing')
    
    try:
        model = genai.GenerativeModel(model_name="gemini-1.5-pro-latest")
        response = model.generate_content(["ƒê√¢y l√† b·ª©c ·∫£nh g√¨?", img])
        add_to_chat_history(user_id, "Human", "G·ª≠i m·ªôt b·ª©c ·∫£nh")
        add_to_chat_history(user_id, "AI", f"M√¥ t·∫£ ·∫£nh: {response.text}")
        bot.send_message(message.chat.id, response.text)
    except Exception as e:
        bot.send_message(message.chat.id, 'D·ªãch v·ª• kh√¥ng ph·∫£n h·ªìi, vui l√≤ng th·ª≠ l·∫°i sau.')

@bot.message_handler(func=lambda message: message.chat.type == 'private' and not message.text.startswith('/'))
def handle_private_message(message):
    user_id = message.from_user.id
    first_name = message.from_user.first_name
    question = message.text.strip()
    if not question:
        bot.send_message(message.chat.id, 'B·∫°n c·∫ßn nh·∫≠p c√¢u h·ªèi.')
        return

    bot.send_chat_action(message.chat.id, 'typing')
    formatted_question = f"T√¥i l√† {first_name}, t√¥i mu·ªën h·ªèi: {question}"
    add_to_chat_history(user_id, "Human", formatted_question)
    
    history = get_chat_history(user_id)
    full_prompt = f"{training_instruction}\n\nL·ªãch s·ª≠ tr√≤ chuy·ªán:\n{format_chat_history(history)}\n\nHuman: {formatted_question}\nAI:"
    
    response = generate_response(full_prompt)
    if response:
        add_to_chat_history(user_id, "AI", response)
        bot.send_message(message.chat.id, response)
    else:
        bot.send_message(message.chat.id, 'D·ªãch v·ª• kh√¥ng ph·∫£n h·ªìi, vui l√≤ng th·ª≠ l·∫°i sau.')

while True:
    try:
        bot.polling(none_stop=True)
    except Exception as e:
        time.sleep(15)  # ƒê·ª£i 15 gi√¢y tr∆∞·ªõc khi th·ª≠ l·∫°i